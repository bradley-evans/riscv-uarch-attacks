/* 
 * Copyright 2020 Bradley Evans
 *
 * This program was developed to satisfy requirements
 * for the Masters Degree in Computer Engineering at
 * the University of California, Riverside. Refer to
 * the associated thesis for details.
 *
 * This program is based on Mastik by Yuval Yarom.
 */

/**
 * @file low.h
 * @author Bradley Evans
 * @date 27 May 2020
 * @brief Low level common functions for RISC-V side-channel attacks.
 */

#ifndef __LOW_H__
#define __LOW_H__


#include <math.h>
#include <stdint.h>
#include <stdio.h>
#include <dirent.h>
#include <stdlib.h>
#include <string.h>


#include "util.h"
#include "debug_log.h"


/**
 * @brief      Defines CPU cache parameters.
 * This should be dynamically generated by reading sysfiles in
 * a Linux operating system. Exists as a struct within a cpu
 * struct. 
 */
struct cache_t {
    int ways; /*!< Number of cache ways. */
    int level; /*!< Level of this cache, eg L1. */
    int size; /*!< Size of cache, bytes. */
    int sets; /*!< Number of sets in this cache. */
    int linesize; /*!< Cache line size, bytes */
    int blocksize; /*!< The system block size, bytes. */
    char * type; /*!< String for instruction, data cache, etc. */
    // derived properties
    int numbits_Offset; /*!< Number of offset bits for an address in this system. */
    int numbits_Set; /*!< Number of bits used for indexing. */
    int numbits_Tag; /*!< Number of bits used for tag. */
    uint64_t mask_Offset; /*!< Masks to derive offset. */
    uint64_t mask_Set; /*!< Masks to derive set. */
    uint64_t mask_Tag; /*!< Masks to derive tag. */
};


/**
 * @brief      Defines CPU parameters.
 */
struct cpu_t {
    int hart; /*!< The hart ID or cpuID of the core. */
    int numCaches; /*!< The number of cache levels this core contains. */
    struct cache_t * cache; /*!< An array of cache structs associated with the core. */
};


/**
 * @brief      This helper function will perform a memory access. Returns an int of what 
 * was found at that address. Used to force memory accesses to specific 
 * locations. This method was suggested by Stef O'Rear. It would be good to 
 * examine if compiler optimizations actually affect this. 
 * 
 * @param      address A memory address. 64-bit.
 */
static inline int primitive_load(void *address) {
    return *(volatile int *)address;
}


/**
 * @brief      This helper function will perform a memory write to a specific address.
 * Returns nothing. Usage storeword(target_addr).
 * 
 * @param      address A memory address. 64-bit.
 */
static inline void primitive_store(void *address) {
    char value = '0';
    *(volatile int *)address = value;
}


/* ==============================================================
 * x86_64 FUNCTIONS
 * ==============================================================
 */
#ifdef __x86_64


/**
 * @brief      Calls cpuid, which serializes the instruction stream in x86.
 */
static inline void _x86_64_cpuid() {
    int a = 0x1, b, c=0, d;
    asm volatile(
        "cpuid\n\t"
        : "=a" (a), "=b" (b), "=c" (c), "=d" (d)
        : "0" (a), "2" (c)
    );
}


/**
 * @brief      Read cycle count in x86.
 *
 * @return     The cycle count in x86.
 */
static inline uint64_t _x86_64_rdtsc() {
    unsigned int lo, hi;
    asm volatile(
        "rdtsc"
        : "=a" (lo), "=d" (hi)
    );

    char *msg = malloc(100);
    sprintf(msg, "cycles: %ld", ((uint64_t)hi << 32) | lo);
    debug_msg(msg);
    return ((uint64_t)hi << 32) | lo;
}


#endif /* __x86_84 */


/* ==============================================================
 * RISCV-V FUNCTIONS
 * ==============================================================
 */
#ifdef __riscv


/**
 * @brief      Uses a RISC-V CSR instruction to serialize the instruction stream.
 * 
 * Uses a CSR instruction to serialize the instruction stream. A serialization
 * instruction does not actually exist in RISC-V, however, the documentation
 * for the Berkeley Out-of-Order Machine (BOOM) indicates that Control Status
 * Register instructions may have a serializing effect. We use rdinstret to
 * leverage this property. This function will return the retired instruction
 * count on the processor. 
 * 
 * @return     register value
 */
static inline uint64_t _riscv_rdinstret() {
    uint64_t rv;
    asm volatile(
        "rdinstret %[rv]"
        : [rv]"=r" (rv)
    );
    return rv;
}


/**
 * @brief      Returns number of cycles elapsed since some arbitrary point of time.
 *
 * @return     The cycle count.
 */
static uint64_t _riscv_rdcycle() {
    uint64_t cycles = 0;
    asm volatile(   
        "fence\n"
        "rdcycle %[cycles]\n"
        : [cycles]"=r" (cycles)
    );
    return cycles;
}


/**
 * @brief      Will flush an L1 DCache associated with addr.
 * 
 * Taken from a BOOM core attack demonstration located at
 * https://github.com/riscv-boom/boom-attacks/blob/master/inc/cache.h.
 * Modified for this project. The general idea is that we generate an
 * array that takes up some multiple of the size of the cache. The
 * array gets instantiated as contiguous memory, so we in theory
 * will have multiple addresses that correspond to each cache line.
 * Then reading over this array a few times should flush the cache.
 * Note that this doesn't work if your objective is flushing the
 * dummyMem var itself from cache, which seems a little silly to
 * need to do anyway.
 * 
 * @ingroup    low
 * @param[in]  addr       The address we would like to flush from cache.
 * @param[in]  sz         The size of the area of memory we need to flush from cache.
 * @param[in]  cache      L1 DCache parameters
 */
static void _riscv_flushCache(uint64_t addr, uint64_t sz, struct cache_t cache ) {
    // uint8_t has size 1 (bytes)
    uint64_t start_cycle = _riscv_rdcycle();
    uint8_t dummyMem[5 * cache.size]; //!< Creates an array at least the size of the cache.

    // Determine the number of blocks we need to clear.
    uint64_t numSetsClear = sz >> cache.numbits_Offset; //!< Number of blocks we need to clear.
    if ( (sz & cache.mask_Offset) != 0 ) {
        numSetsClear += 1;
    }
    if (numSetsClear > cache.sets) {
        // Case when the number of sets to clear
        // is greater than the size of the cache, e.g.
        // an array with a size larger than the cache.
        // Flush the entire cache, no rollover.
        numSetsClear = cache.sets;
    }


    uint8_t dummyVar = 0; //!< Dummy var used to perform memory reads.
    uint64_t alignedMem = ((uint64_t)&dummyMem + cache.size) & cache.mask_Tag;  //!< Memory space aligned on the first space in dummyMem with set and offset = 0

    // This is the essential loop that will clear out the targeted set 
    for (uint64_t i=0; i<numSetsClear; ++i) {
        uint64_t setOffset = (((addr & cache.mask_Set) >> cache.numbits_Offset) + i) << cache.numbits_Offset;
        for (uint64_t j=0; j<4*cache.ways; ++j) {
            uint64_t wayOffset = j << (cache.numbits_Offset + cache.numbits_Set);
            dummyVar = *((uint8_t*)(alignedMem + setOffset + wayOffset));
        }
    }
    uint64_t end_cycle = _riscv_rdcycle();
}


#endif /* __riscv */


/*
 * Function prototypes for device tree reader
 */
int get_numCaches(int hart_id);
int get_numCPUOnline();
struct cache_t get_CacheParameters(int hart_id, int cache_index);
struct cpu_t get_CPUParameters(int hart_id);
struct cpu_t* initialize_cpu();
struct cache_t getL1DCache();
void notimplemented();


/*
 * ISA specific function default macros.
 */

#define asm_load(arg) 0 /*!< Macro for an ISA-specific load operation. */
#define asm_store(arg) 0 /*!< Macro for an ISA-specific store operation. */
#define serialize() 0 /*!< Macro for ISA-specific serialization functions. */
#define flushcache(addr, sz, l1_dcache) 0 /*!< Macro for ISA-specific cache-flush functions. */
#define cycles() 0 /*!< Macro for ISA-specific cycle-count operations. */

/*
 * ISA-specific macro definitions.
 */

#ifdef __riscv
    #undef asm_load
    #undef asm_store
    #undef serialize
    #undef flushcache
    #undef cycles
    

    #define asm_load(arg) primitive_load(arg)
    #define asm_store(arg) primitive_store(arg)
    #define serialize() _riscv_rdinstret()
    #define flushcache(addr, sz, cache) _riscv_flushCache(addr, sz, cache)
    #define cycles() _riscv_rdcycle()
#endif


#ifdef __x86_64
    #undef asm_load
    #undef asm_store
    #undef serialize
    #undef cycles

    #define asm_load(arg) primitive_load(arg)
    #define asm_store(arg) primitive_store(arg)
    #define serialize() _x86_64_cpuid()
    #define cycles() _x86_64_rdtsc()
#endif


#endif /* __LOW_H__ */
